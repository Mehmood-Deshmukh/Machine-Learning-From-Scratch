# Machine Learning from Scratch

This repository contains implementations of various machine learning algorithms from scratch using only numpy.

## Table of Contents

- [Algorithms](#algorithms)
  - [Linear Regression](#linear-regression)
  - [Logistic Regression](#logistic-regression)
  - [Decision Tree](#decision-tree)
  - [Random Forest](#random-forest)
  - [K-Means](#k-means)
  - [K-Nearest Neighbours](#k-nearest-neighbours)
  - [Principal Component Analysis (PCA)](#principal-component-analysis-pca)
  - [Linear Discriminant Analysis](#linear-discriminant-analysis)
  - [Naive Bayes](#naive-bayes)
  - [Perceptron](#perceptron)
  - [Support Vector Machine](#support-vector-machine)
  - [AdaBoost](#adaboost)

## Algorithms
### Linear Regression
This algorithm predicts a continuous target variable based on linear relationships between variables.
<hr>

### Logistic Regression
A statistical method for binary classification that models the probability of a certain class or event.
<hr>

### Decision Tree
A decision tree algorithm used for both classification and regression tasks, which models decisions and their possible consequences as a tree structure.
<hr>

### Random Forest
An ensemble learning method that operates by constructing a multitude of decision trees during training and outputting the mode or mean prediction of the individual trees.
<hr>

### K-Means
An unsupervised learning algorithm for clustering data into K distinct groups based on feature similarity.
<hr>

### K-Nearest Neighbours
A simple, instance-based learning algorithm used for classification and regression by comparing new data points to known data points.
<hr>

### Principal Component Analysis (PCA)
An unsupervised learning technique used for dimensionality reduction while preserving as much variance as possible.
<hr>

### Linear Discriminant Analysis
A classification algorithm that projects data onto a lower-dimensional space with good class-separability to avoid overfitting.
<hr>

### Naive Bayes
A probabilistic classifier based on applying Bayes' theorem with strong (naive) independence assumptions between the features.
<hr>

### Perceptron
The perceptron is the simplest type of artificial neural network and is used for binary classification tasks.
<hr>

### Support Vector Machine
A supervised learning algorithm used for classification and regression tasks, which finds the optimal hyperplane that best separates the data into classes.
<hr>

### AdaBoost
Implementation of the AdaBoost algorithm, a powerful ensemble method that combines the predictions of several base estimators to improve robustness.

